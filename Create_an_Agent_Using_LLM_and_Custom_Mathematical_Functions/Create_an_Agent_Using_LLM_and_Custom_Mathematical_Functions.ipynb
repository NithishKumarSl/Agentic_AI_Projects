{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LppKJwJ7DPu"
      },
      "outputs": [],
      "source": [
        "# Install packages one by one with proper versions\n",
        "!pip install -q langgraph\n",
        "!pip install -q langchain\n",
        "!pip install -q langchain-google-genai\n",
        "!pip install -q langchain-community\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q gradio\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")\n",
        "print(\"‚ö†Ô∏è  IMPORTANT: Please restart runtime now (Runtime > Restart Runtime)\")\n",
        "print(\"Then run the next cell...\")\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Try to get API key from Colab secrets\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"‚úÖ API Key loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Could not load API key from secrets\")\n",
        "    print(\"Please add your Google API key:\")\n",
        "    print(\"1. Click the key icon üîë on the left sidebar\")\n",
        "    print(\"2. Add a new secret with name: GOOGLE_API_KEY\")\n",
        "    print(\"3. Paste your Gemini API key as the value\")\n",
        "    print(\"4. Run this cell again\")\n",
        "\n",
        "    # Alternative: Set API key directly (less secure)\n",
        "    GOOGLE_API_KEY = input(\"Or enter your API key here: \").strip()\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(\"API key is required!\")\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "print(\"üîë API Key configured successfully!\")\n",
        "\n",
        "import operator\n",
        "import gradio as gr\n",
        "from typing import TypedDict, List, Optional, Annotated, Union\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "print(\"üöÄ Ready to create the LangGraph agent!\")\n",
        "\n",
        "# Initialize Gemini 1.5 Flash LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"ü§ñ Gemini LLM initialized successfully!\")\n",
        "\n",
        "# Define the State for LangGraph\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    user_input: str\n",
        "    agent_outcome: Optional[Union[BaseMessage, List[tuple]]]\n",
        "    intermediate_steps: List\n",
        "\n",
        "# Define the four mathematical operation tools as required\n",
        "\n",
        "@tool\n",
        "def plus(a: float, b: float) -> float:\n",
        "    \"\"\"Add two numbers together. Use this tool for addition problems.\n",
        "\n",
        "    Args:\n",
        "        a: First number to add\n",
        "        b: Second number to add\n",
        "\n",
        "    Returns:\n",
        "        The sum of a and b\n",
        "    \"\"\"\n",
        "    result = a + b\n",
        "    print(f\"üîß Tool called: plus({a}, {b}) = {result}\")\n",
        "    return result\n",
        "\n",
        "@tool\n",
        "def subtract(a: float, b: float) -> float:\n",
        "    \"\"\"Subtract the second number from the first number. Use this tool for subtraction problems.\n",
        "\n",
        "    Args:\n",
        "        a: Number to subtract from\n",
        "        b: Number to subtract\n",
        "\n",
        "    Returns:\n",
        "        The difference (a - b)\n",
        "    \"\"\"\n",
        "    result = a - b\n",
        "    print(f\"üîß Tool called: subtract({a}, {b}) = {result}\")\n",
        "    return result\n",
        "\n",
        "@tool\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers together. Use this tool for multiplication problems.\n",
        "\n",
        "    Args:\n",
        "        a: First number to multiply\n",
        "        b: Second number to multiply\n",
        "\n",
        "    Returns:\n",
        "        The product of a and b\n",
        "    \"\"\"\n",
        "    result = a * b\n",
        "    print(f\"üîß Tool called: multiply({a}, {b}) = {result}\")\n",
        "    return result\n",
        "\n",
        "@tool\n",
        "def divide(a: float, b: float) -> Union[float, str]:\n",
        "    \"\"\"Divide the first number by the second number. Use this tool for division problems.\n",
        "    Includes error handling for division by zero.\n",
        "\n",
        "    Args:\n",
        "        a: Dividend (number to be divided)\n",
        "        b: Divisor (number to divide by)\n",
        "\n",
        "    Returns:\n",
        "        The quotient (a / b) or error message if dividing by zero\n",
        "    \"\"\"\n",
        "    if b == 0:\n",
        "        error_msg = \"Error: Cannot divide by zero\"\n",
        "        print(f\"üîß Tool called: divide({a}, {b}) = {error_msg}\")\n",
        "        return error_msg\n",
        "\n",
        "    result = a / b\n",
        "    print(f\"üîß Tool called: divide({a}, {b}) = {result}\")\n",
        "    return result\n",
        "\n",
        "# List of all available tools\n",
        "tools = [plus, subtract, multiply, divide]\n",
        "\n",
        "print(f\"üõ†Ô∏è  Created {len(tools)} mathematical tools: {[tool.name for tool in tools]}\")\n",
        "\n",
        "# Enhanced system prompt to guide the agent's behavior\n",
        "system_prompt = \"\"\"You are a helpful and intelligent assistant that can:\n",
        "1. Answer general knowledge questions using your built-in knowledge\n",
        "2. Perform mathematical calculations using the provided tools when requested\n",
        "\n",
        "IMPORTANT INSTRUCTIONS:\n",
        "- For mathematical operations (addition, subtraction, multiplication, division), ALWAYS use the appropriate tools\n",
        "- For general questions, respond using your knowledge without using tools\n",
        "- Be clear and helpful in your responses\n",
        "- When using math tools, explain what calculation you're performing\n",
        "- Handle edge cases like division by zero appropriately\n",
        "\n",
        "Available math tools:\n",
        "- plus(a, b): For addition operations\n",
        "- subtract(a, b): For subtraction operations\n",
        "- multiply(a, b): For multiplication operations\n",
        "- divide(a, b): For division operations (with zero-division protection)\n",
        "\n",
        "Format all responses clearly and professionally.\"\"\"\n",
        "\n",
        "# Create the tool-calling agent\n",
        "agent = create_tool_calling_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]),\n",
        ")\n",
        "\n",
        "# Create agent executor with verbose output\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "print(\"üéØ Agent and executor created successfully!\")\n",
        "\n",
        "# Define the agent node for the LangGraph workflow\n",
        "def agent_node(state: AgentState):\n",
        "    \"\"\"Execute the agent with the current state\"\"\"\n",
        "    try:\n",
        "        result = agent_executor.invoke({\n",
        "            \"input\": state[\"user_input\"],\n",
        "            \"chat_history\": state[\"messages\"]\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            \"messages\": [AIMessage(content=result[\"output\"])],\n",
        "            \"agent_outcome\": result[\"output\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        error_message = f\"I encountered an error: {str(e)}. Please try rephrasing your question.\"\n",
        "        return {\n",
        "            \"messages\": [AIMessage(content=error_message)],\n",
        "            \"agent_outcome\": error_message\n",
        "        }\n",
        "\n",
        "# Build the LangGraph workflow\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add the agent node\n",
        "workflow.add_node(\"agent\", agent_node)\n",
        "\n",
        "# Set entry point and define flow\n",
        "workflow.set_entry_point(\"agent\")\n",
        "workflow.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"üîó LangGraph workflow compiled successfully!\")\n",
        "\n",
        "def run_agent(query: str, chat_history: List[BaseMessage] = None) -> str:\n",
        "    \"\"\"Execute the agent with a user query using LangGraph\n",
        "\n",
        "    Args:\n",
        "        query: User's input query\n",
        "        chat_history: Previous conversation messages\n",
        "\n",
        "    Returns:\n",
        "        Agent's response as a string\n",
        "    \"\"\"\n",
        "    if chat_history is None:\n",
        "        chat_history = []\n",
        "\n",
        "    try:\n",
        "        inputs = {\n",
        "            \"messages\": chat_history,\n",
        "            \"user_input\": query,\n",
        "            \"agent_outcome\": None,\n",
        "            \"intermediate_steps\": []\n",
        "        }\n",
        "\n",
        "        response = app.invoke(inputs)\n",
        "        return str(response[\"agent_outcome\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error processing your request: {str(e)}\"\n",
        "\n",
        "print(\"üöÄ Agent is ready for testing!\")\n",
        "\n",
        "def test_agent():\n",
        "    \"\"\"Test the agent with sample queries\"\"\"\n",
        "    test_queries = [\n",
        "        \"What is 5 plus 3?\",\n",
        "        \"Tell me about artificial intelligence\",\n",
        "        \"What is 15 multiplied by 4?\",\n",
        "        \"What is 100 divided by 5?\",\n",
        "        \"What is the largest planet in our solar system?\",\n",
        "        \"Calculate 20 minus 8\"\n",
        "    ]\n",
        "\n",
        "    print(\"üß™ Testing the agent with sample queries...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nüî∏ Test {i}: {query}\")\n",
        "        response = run_agent(query)\n",
        "        print(f\"ü§ñ Response: {response}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Run the tests\n",
        "test_agent()\n",
        "\n",
        "class ChatInterface:\n",
        "    def __init__(self):\n",
        "        self.chat_history = []\n",
        "\n",
        "    def chat_function(self, message, history):\n",
        "        \"\"\"Process chat messages and maintain history\"\"\"\n",
        "        if not message.strip():\n",
        "            return history, \"\"\n",
        "\n",
        "        # Convert Gradio history to LangChain format\n",
        "        langchain_history = []\n",
        "        for human_msg, ai_msg in history:\n",
        "            if human_msg:\n",
        "                langchain_history.append(HumanMessage(content=human_msg))\n",
        "            if ai_msg:\n",
        "                langchain_history.append(AIMessage(content=ai_msg))\n",
        "\n",
        "        # Get agent response\n",
        "        response = run_agent(message, langchain_history)\n",
        "\n",
        "        # Update history\n",
        "        history.append((message, response))\n",
        "\n",
        "        return history, \"\"\n",
        "\n",
        "# Create the interface\n",
        "chat_interface = ChatInterface()\n",
        "\n",
        "# Define the Gradio interface\n",
        "def create_gradio_interface():\n",
        "    with gr.Blocks(title=\"LangGraph Math & Q&A Agent\", theme=gr.themes.Soft()) as interface:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ü§ñ LangGraph Math & Q&A Agent\n",
        "\n",
        "        This intelligent agent can:\n",
        "        - **Answer general questions** using advanced AI knowledge\n",
        "        - **Perform mathematical calculations** using specialized tools:\n",
        "          - ‚ûï Addition (plus)\n",
        "          - ‚ûñ Subtraction (subtract)\n",
        "          - ‚úñÔ∏è Multiplication (multiply)\n",
        "          - ‚ûó Division (divide) with zero-division protection\n",
        "\n",
        "        ### Examples to try:\n",
        "        - *\"What is the capital of France?\"*\n",
        "        - *\"What is 15 plus 27?\"*\n",
        "        - *\"Calculate 144 divided by 12\"*\n",
        "        - *\"Tell me about machine learning\"*\n",
        "        - *\"What is 8 times 7?\"*\n",
        "        \"\"\")\n",
        "\n",
        "        chatbot = gr.Chatbot(\n",
        "            height=500,\n",
        "            show_label=False,\n",
        "            container=True,\n",
        "            bubble_full_width=False\n",
        "        )\n",
        "\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Ask me anything or request a math calculation...\",\n",
        "            show_label=False,\n",
        "            container=False\n",
        "        )\n",
        "\n",
        "        clear = gr.Button(\"üóëÔ∏è Clear Chat\")\n",
        "\n",
        "        def respond(message, chat_history):\n",
        "            return chat_interface.chat_function(message, chat_history)\n",
        "\n",
        "        msg.submit(respond, [msg, chatbot], [chatbot, msg])\n",
        "        clear.click(lambda: [], None, chatbot, queue=False)\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **Note**: This agent uses Google's Gemini 1.5 Flash model and LangGraph for intelligent routing between general Q&A and mathematical operations.\n",
        "        \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "print(\"üé® Creating Gradio interface...\")\n",
        "\n",
        "# Launch the interface\n",
        "interface = create_gradio_interface()\n",
        "print(\"üöÄ Launching Gradio interface with public link...\")\n",
        "\n",
        "interface.launch(\n",
        "    share=True,  # Creates a public link for sharing\n",
        "    debug=True,\n",
        "    show_error=True,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LangGraph Agent is now running!\")\n",
        "print(\"üåê Use the public link above to access your agent from anywhere!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCcFHw79_Ybl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
